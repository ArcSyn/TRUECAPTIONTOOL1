/**
 * JSX Export Service for After Effects
 * Converts SRT captions to After Effects JSX scripts with styling and scene support
 */

const fs = require('fs').promises;
const path = require('path');

class JSXExportService {
  constructor() {
    this.defaultStyles = {
      modern: {
        font: "Arial-Bold", 
        fontSize: 65,
        color: [1, 1, 1], // White
        strokeColor: [0, 0, 0], // Black
        strokeWidth: 3,
        position: [0.5, 0.85], // Relative to comp (center bottom)
        justification: "CENTER_JUSTIFY",
        animation: "fadeIn",
        shadow: true,
        shadowColor: [0, 0, 0, 0.7],
        shadowDistance: 5
      },
      minimal: {
        font: "Helvetica-Light",
        fontSize: 48,
        color: [1, 1, 1],
        strokeColor: null,
        strokeWidth: 0,
        position: [0.5, 0.9],
        justification: "CENTER_JUSTIFY",
        animation: "none",
        shadow: false
      },
      bold: {
        font: "Impact",
        fontSize: 72,
        color: [1, 1, 0], // Yellow
        strokeColor: [0, 0, 0],
        strokeWidth: 4,
        position: [0.5, 0.8],
        justification: "CENTER_JUSTIFY",
        animation: "slideUp",
        shadow: true,
        shadowColor: [0, 0, 0, 0.8],
        shadowDistance: 8
      }
    };
  }

  /**
   * Parse SRT content into caption objects
   */
  parseSRT(srtContent) {
    const captions = [];
    const blocks = srtContent.trim().split(/\n\s*\n/);
    
    for (const block of blocks) {
      const lines = block.trim().split('\n');
      if (lines.length >= 3) {
        const index = parseInt(lines[0]);
        const timeRange = lines[1];
        const text = lines.slice(2).join(' ');
        
        // Parse time format: 00:00:10,500 --> 00:00:13,240
        const timeMatch = timeRange.match(/(\d{2}):(\d{2}):(\d{2}),(\d{3})\s*-->\s*(\d{2}):(\d{2}):(\d{2}),(\d{3})/);
        if (timeMatch) {
          const startTime = this.parseTime(timeMatch[1], timeMatch[2], timeMatch[3], timeMatch[4]);
          const endTime = this.parseTime(timeMatch[5], timeMatch[6], timeMatch[7], timeMatch[8]);
          
          captions.push({
            id: index,
            startTime,
            endTime,
            text: text.replace(/<[^>]*>/g, ''), // Remove HTML tags
            duration: endTime - startTime
          });
        }
      }
    }
    
    return captions;
  }

  /**
   * Convert time components to seconds
   */
  parseTime(hours, minutes, seconds, milliseconds) {
    return parseInt(hours) * 3600 + 
           parseInt(minutes) * 60 + 
           parseInt(seconds) + 
           parseInt(milliseconds) / 1000;
  }

  /**
   * Break captions into scenes based on gaps
   */
  breakIntoScenes(captions, gapThreshold = 2.0) {
    if (!captions.length) return [];
    
    const scenes = [];
    let currentScene = [captions[0]];
    
    for (let i = 1; i < captions.length; i++) {
      const gap = captions[i].startTime - captions[i - 1].endTime;
      
      if (gap > gapThreshold) {
        // Start new scene
        scenes.push({
          id: scenes.length + 1,
          startTime: currentScene[0].startTime,
          endTime: currentScene[currentScene.length - 1].endTime,
          captions: currentScene,
          duration: currentScene[currentScene.length - 1].endTime - currentScene[0].startTime
        });
        currentScene = [captions[i]];
      } else {
        currentScene.push(captions[i]);
      }
    }
    
    // Add the last scene
    if (currentScene.length > 0) {
      scenes.push({
        id: scenes.length + 1,
        startTime: currentScene[0].startTime,
        endTime: currentScene[currentScene.length - 1].endTime,
        captions: currentScene,
        duration: currentScene[currentScene.length - 1].endTime - currentScene[0].startTime
      });
    }
    
    return scenes;
  }

  /**
   * Generate After Effects JSX code
   */
  generateJSX(captions, options = {}) {
    const {
      projectName = 'Caption Project',
      styleName = 'modern',
      compWidth = 1920,
      compHeight = 1080,
      compDuration = null,
      sceneMode = false
    } = options;

    const style = this.defaultStyles[styleName] || this.defaultStyles.modern;
    const scenes = sceneMode ? this.breakIntoScenes(captions) : null;
    
    if (sceneMode && scenes) {
      return this.generateSceneBasedJSX(scenes, style, options);
    }
    
    return this.generateSingleJSX(captions, style, options);
  }

  /**
   * Generate single JSX file with all captions
   */
  generateSingleJSX(captions, style, options) {
    const { projectName, compWidth = 1920, compHeight = 1080, frameRate = 30, compDuration = 60 } = options;
    
    return `// After Effects Caption Script - ${projectName}
// Generated by CapEdify Enhanced
// Style: ${style.font || 'Default'}
// Segments: ${captions.length} captions with precise timing

function addCaptions() {
    app.beginUndoGroup("Add CapEdify Captions");
    
    try {
        // Create new composition for captions
        var compName = "${projectName} - Captions";
        var comp = app.project.items.addComp(compName, ${compWidth}, ${compHeight}, 1.0, ${compDuration}, ${frameRate});
        
        if (!comp) {
            alert("Failed to create composition.");
            return;
        }
        
        comp.openInViewer();
        // Caption data
        var captions = ${JSON.stringify(captions, null, 8)};
        
        // Style configuration
        var style = ${JSON.stringify(style, null, 8)};
        
        for (var i = 0; i < captions.length; i++) {
            var caption = captions[i];
            var textLayer = comp.layers.addText(caption.text);
            textLayer.name = "Caption " + (i + 1) + " - " + caption.text.substring(0, 20) + "...";
            
            // Set timing
            textLayer.inPoint = caption.startTime;
            textLayer.outPoint = caption.endTime;
            
            // Apply text styling
            var textProp = textLayer.property("Source Text");
            var textDocument = textProp.value;
            
            textDocument.font = style.font;
            textDocument.fontSize = style.fontSize;
            textDocument.fillColor = style.color;
            
            if (style.strokeWidth > 0 && style.strokeColor) {
                textDocument.strokeColor = style.strokeColor;
                textDocument.strokeWidth = style.strokeWidth;
                textDocument.strokeOverFill = true;
            }
            
            textDocument.justification = ParagraphJustification[style.justification];
            textProp.setValue(textDocument);
            
            // Position
            var posX = style.position[0] * comp.width;
            var posY = style.position[1] * comp.height;
            textLayer.property("Position").setValue([posX, posY]);
            
            // Add shadow if enabled
            if (style.shadow) {
                var dropShadow = textLayer.property("Effects").addProperty("Drop Shadow");
                dropShadow.property("Opacity").setValue(180);
                dropShadow.property("Direction").setValue(135);
                dropShadow.property("Distance").setValue(style.shadowDistance || 5);
                dropShadow.property("Softness").setValue(10);
            }
            
            // Add sophisticated animations based on style
            if (style.animation === "fadeIn") {
                var opacity = textLayer.property("Opacity");
                var fadeInDuration = Math.min(0.3, caption.duration * 0.2); // 20% of duration or 0.3s max
                var fadeOutDuration = Math.min(0.2, caption.duration * 0.15); // 15% of duration or 0.2s max
                
                opacity.setValueAtTime(textLayer.inPoint, 0);
                opacity.setValueAtTime(textLayer.inPoint + fadeInDuration, 100);
                opacity.setValueAtTime(textLayer.outPoint - fadeOutDuration, 100);
                opacity.setValueAtTime(textLayer.outPoint, 0);
                
                // Add easing
                for (var k = 1; k <= opacity.numKeys; k++) {
                    opacity.keyTemporalEase(k, [new KeyframeEase(0, 75), new KeyframeEase(0, 75)]);
                }
            } else if (style.animation === "slideUp") {
                var position = textLayer.property("Position");
                var slideDistance = style.fontSize || 50;
                var startPos = [posX, posY + slideDistance];
                var endPos = [posX, posY];
                var slideDuration = Math.min(0.5, caption.duration * 0.3);
                
                position.setValueAtTime(textLayer.inPoint, startPos);
                position.setValueAtTime(textLayer.inPoint + slideDuration, endPos);
                
                // Add easing for smooth motion
                for (var k = 1; k <= position.numKeys; k++) {
                    position.keyTemporalEase(k, [new KeyframeEase(0, 80), new KeyframeEase(0, 80)]);
                }
                
                // Also add fade in
                var opacity = textLayer.property("Opacity");
                opacity.setValueAtTime(textLayer.inPoint, 0);
                opacity.setValueAtTime(textLayer.inPoint + slideDuration, 100);
                opacity.setValueAtTime(textLayer.outPoint - 0.2, 100);
                opacity.setValueAtTime(textLayer.outPoint, 0);
            }
        }
        
        app.endUndoGroup();
        alert("Successfully added " + captions.length + " captions!");
        
    } catch (error) {
        app.endUndoGroup();
        alert("Error adding captions: " + error.toString());
    }
}

// Execute the function
addCaptions();
`;
  }

  /**
   * Generate scene-based JSX files
   */
  generateSceneBasedJSX(scenes, style, options) {
    const { projectName } = options;
    const jsxFiles = {};
    
    // Master JSX that imports all scenes
    jsxFiles['master.jsx'] = this.generateMasterJSX(scenes, projectName);
    
    // Individual scene JSX files
    scenes.forEach((scene, index) => {
      const sceneNumber = String(index + 1).padStart(3, '0');
      jsxFiles[`scene_${sceneNumber}.jsx`] = this.generateSingleJSX(
        scene.captions, 
        style, 
        { ...options, projectName: `${projectName} - Scene ${scene.id}` }
      );
    });
    
    return jsxFiles;
  }

  /**
   * Generate master JSX that can import all scenes
   */
  generateMasterJSX(scenes, projectName) {
    return `// Master Scene Controller - ${projectName}
// Generated by CaptionFlow Enhanced

function importAllScenes() {
    alert("Master scene controller loaded. Import individual scene files to add captions.");
    
    var sceneInfo = ${JSON.stringify(scenes.map(scene => ({
      id: scene.id,
      startTime: scene.startTime,
      endTime: scene.endTime,
      duration: scene.duration,
      captionCount: scene.captions.length
    })), null, 4)};
    
    var info = "Scene Breakdown:\\n";
    for (var i = 0; i < sceneInfo.length; i++) {
        var scene = sceneInfo[i];
        info += "Scene " + scene.id + ": " + 
                scene.startTime.toFixed(1) + "s - " + 
                scene.endTime.toFixed(1) + "s (" + 
                scene.captionCount + " captions)\\n";
    }
    
    alert(info);
}

importAllScenes();
`;
  }

  /**
   * Export captions to JSX format(s)
   */
  async exportToJSX(transcriptionId, options = {}) {
    try {
      const { captions, srtContent } = options;
      
      let captionData = captions;
      let videoMetadata = null;
      
      // If no captions provided, fetch from database using transcriptionId
      if (!captionData && !srtContent && transcriptionId) {
        const { createClient } = require('@supabase/supabase-js');
        const supabase = createClient(
          process.env.SUPABASE_URL,
          process.env.SUPABASE_SERVICE_ROLE
        );
        
        // First get transcription data
        const { data: transcription, error } = await supabase
          .from('transcriptions')
          .select('result, video_id')
          .eq('id', transcriptionId)
          .single();
          
        if (error || !transcription) {
          throw new Error(`Failed to fetch transcription: ${error?.message || 'Not found'}`);
        }
        
        // Try to get video metadata if video_id exists
        if (transcription.video_id) {
          try {
            const { data: video, error: videoError } = await supabase
              .from('videos')
              .select('metadata')
              .eq('id', transcription.video_id)
              .single();
              
            if (!videoError && video?.metadata) {
              videoMetadata = video.metadata;
              console.log('ðŸŽ¯ Using video metadata for JSX generation:', {
                resolution: `${videoMetadata.width}x${videoMetadata.height}`,
                frameRate: `${videoMetadata.frameRate}fps`,
                duration: `${videoMetadata.duration}s`
              });
            }
          } catch (metadataError) {
            console.log('â„¹ï¸ No video metadata found, using defaults');
          }
        }
        
        if (transcription.result) {
          // Use segments if available (preferred for timing accuracy)
          if (transcription.result.segments && transcription.result.segments.length > 0) {
            console.log(`ðŸŽ¯ Using ${transcription.result.segments.length} segments with precise timing`);
            captionData = transcription.result.segments.map((segment, index) => ({
              id: index + 1,
              startTime: segment.start || 0,
              endTime: segment.end || (segment.start + 3),
              text: (segment.text || '').trim(),
              duration: (segment.end || (segment.start + 3)) - (segment.start || 0)
            })).filter(segment => segment.text.length > 0); // Remove empty segments
          } 
          // Fallback to single caption if no segments
          else if (transcription.result.text) {
            console.log('âš ï¸ No segments available, creating single caption');
            captionData = [{
              id: 1,
              startTime: 0,
              endTime: 10, // Default duration
              text: transcription.result.text,
              duration: 10
            }];
          }
        }
      }
      
      // If still no data, try parsing SRT content
      if (!captionData && srtContent) {
        captionData = this.parseSRT(srtContent);
      }
      
      if (!captionData || captionData.length === 0) {
        throw new Error('No caption data available for export');
      }
      
      // Add video metadata to options for JSX generation
      const enhancedOptions = {
        ...options,
        compWidth: videoMetadata?.width || options.compWidth || 1920,
        compHeight: videoMetadata?.height || options.compHeight || 1080,
        frameRate: videoMetadata?.frameRate || options.frameRate || 30,
        compDuration: videoMetadata?.duration || options.compDuration || 60
      };
      
      const jsxResult = this.generateJSX(captionData, enhancedOptions);
      
      return {
        success: true,
        data: jsxResult,
        metadata: {
          captionCount: captionData.length,
          totalDuration: captionData[captionData.length - 1]?.endTime || 0,
          style: options.styleName || 'modern',
          sceneMode: options.sceneMode || false
        }
      };
      
    } catch (error) {
      console.error('JSX Export Error:', error);
      return {
        success: false,
        error: error.message
      };
    }
  }

  /**
   * Get available styles
   */
  getAvailableStyles() {
    return Object.keys(this.defaultStyles).map(key => ({
      name: key,
      displayName: key.charAt(0).toUpperCase() + key.slice(1),
      config: this.defaultStyles[key]
    }));
  }
}

module.exports = new JSXExportService();
